{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5483a96-9445-4aca-acee-d8ed9e872fb2",
   "metadata": {},
   "source": [
    "## Install Gemini GenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08c97e09-fb17-4e23-b1be-56c13aea9212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (0.7.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-generativeai) (0.6.6)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-generativeai) (2.19.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-generativeai) (2.139.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-generativeai) (2.32.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-generativeai) (4.25.4)\n",
      "Requirement already satisfied: pydantic in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-generativeai) (2.8.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-generativeai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-ai-generativelanguage==0.6.6->google-generativeai) (1.24.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-api-core->google-generativeai) (1.63.2)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from pydantic->google-generativeai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\prabh\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->google-generativeai) (0.4.4)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.65.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.62.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\prabh\\appdata\\roaming\\python\\python310\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.8)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8efc02-c480-4532-bcd8-3e5687a31b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prabh\\anaconda3\\envs\\streamlit_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c9aa0b6-f6d8-4948-ba26-f66bdb79091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"keys/.googleapi.txt\")\n",
    "key = f.read()\n",
    "genai.configure(api_key = key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a3f7f7-0853-41df-96d2-4408a9dd3421",
   "metadata": {},
   "source": [
    "### Available Gemini Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be6c2ae-9def-4528-9521-dcd5f00f8a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/aqa\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4cb057-c394-4c9c-bdea-702d13c141ee",
   "metadata": {},
   "source": [
    "### Prompt to the Gemini model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd35cd60-b44e-4976-82ca-83f86be5a9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISRO stands for **Indian Space Research Organisation**. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
    "user_prompt = \"\"\" Chandrayan is a space mission of ISRO from india. can you tell\"\"\"\n",
    "response = model.generate_content(user_prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ffb258f-769a-4e56-aa52-bfefad42db41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISRO is India's **space research organization**, and it is responsible for developing and operating India's space program. ISRO has launched numerous satellites and conducted several successful missions, including the Chandrayaan lunar missions and the Mangalyaan mission to Mars. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"Generate some factual information to complete the following in 2-3 lines:\n",
    "                ISRO is india's space station and it \"\"\"\n",
    "response = model.generate_content(user_prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1227eb4-e10c-4c97-82cf-fff485371de2",
   "metadata": {},
   "source": [
    "### Adding a System Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635bf65e-4690-4085-af6f-3c68dd181e44",
   "metadata": {},
   "source": [
    "**Important Note:** System Prompt can be specified using <mark style=\"background-color: lightblue;\">system_instruction</mark>. <mark style=\"background-color: lightblue;\">system_instruction </mark> is not enabled for models/gemini-pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "287e763c-7bc4-4846-91cf-59bba467bee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In our solar system, Earth is a **rocky planet**. It's the third planet from the Sun and the only one known to support life. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name= \"gemini-1.5-flash\",\n",
    "                              system_instruction= \"\"\"Generate some factual information to complete the user input. \n",
    "                              Completion must have maximum 2-3 lines.\"\"\")\n",
    "user_prompt = \"\"\"In our solar system, Earth is a\"\"\"\n",
    "response = model.generate_content(user_prompt)\n",
    "print(response.text)\n",
    "                              \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97d093-55b0-4a21-b99b-e73b1e167339",
   "metadata": {},
   "source": [
    "## Important Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d169d1d1-a0de-462a-9312-7c8caec3becc",
   "metadata": {},
   "source": [
    "If you run the above code few times, you will notice that the output changes across runs. Generative models are **non-deterministic**. This means that even with the same input they can produce different outputs. This behavior allows for creativity and diversity in the generated outputs, which can be great when trying to generate different creative styles. There are parameters which can help us control this behavior like temperature, top_p, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7345f2-ca40-4780-9fa9-c4ba4288702f",
   "metadata": {},
   "source": [
    "* **candidate_count:** This controls the number of responses that will be generated for a single prompt. Default value is 1. Increasing this will generate more text responses. This increase the resource usage.\n",
    "* **stop_sequence:** It allows to specify a list of strings that will act as stopsigns for the model.\n",
    "* **max_output_tokens:** This is the maximum number of tokens the model will generate in the response.\n",
    "* **temperature:** It act as a control knob that influences the randomness of the model's output. A higher temperature value will result in a more varied and creative response. Lower values would be more effective in returning predictable results with an LLM.\n",
    "* **top_p:** Range from [0.0, 1.0]. This is also known a nucleus sampling. The LLM only considers the next word options that cumulatively add up to a probability of reaching or exceeding the top_p value. A higher value will create looser threshold. This will allow the model to consider a wider range of probable options while still prioritizing the most likely ones. A lower top_p value will create a stricter threshold, leading to less diverse and more predictable outputs.\n",
    "* **top_k:** This parameter limits the number of possible next words to the k most probable options based on the probability distribution. A lower k value restricts the selection to a smaller pool of the most likely words, leading to less diverse and more predictable outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230581a9-3b7d-4103-8393-ba76dfa93a0a",
   "metadata": {},
   "source": [
    "Both <mark>top_p</mark> and <mark>top_k</mark> works in conjunction with the <mark>temperature</mark> parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed291481-624a-493a-b92c-3bd7fa94c856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Overfitting in Data Science: A Detailed Explanation\n",
      "\n",
      "Overfitting is a common problem in machine learning, occurring when a model learns the training data too well, capturing even the noise and random fluctuations. This results in a model that performs exceptionally well on the training data but poorly on unseen data, making it useless for real-world applications.\n",
      "\n",
      "**Here's a detailed breakdown:**\n",
      "\n",
      "**1. The Ideal Scenario:**\n",
      "\n",
      "- We aim to build models that generalize well, meaning they can accurately predict outcomes on new, unseen data.\n",
      "- The model should capture the underlying patterns and relationships within the data, not just memorize the specific instances in the training set.\n",
      "\n",
      "**2. Overfitting: The Problem:**\n",
      "\n",
      "- Overfitting occurs when a model learns the training data too well, including its noise and outliers.\n",
      "- It creates a model that is highly complex, often with many parameters, resulting in a \"memorization\" of the training data rather than understanding its underlying patterns.\n",
      "- This leads to poor performance on unseen data, as the model struggles to adapt to new inputs.\n",
      "\n",
      "**3. Visualizing Overfitting:**\n",
      "\n",
      "Imagine trying to fit a curve through a set of data points:\n",
      "\n",
      "- **Underfitting:** The curve is too simple and doesn't capture the trend in the data.\n",
      "- **Just Right:** The curve fits the data well without being too complex, capturing the underlying patterns.\n",
      "- **Overfitting:** The curve is too complex and \"hugs\" the data points too closely, including the noise and outliers. This will lead to poor performance on unseen data.\n",
      "\n",
      "**4. Causes of Overfitting:**\n",
      "\n",
      "- **High model complexity:** Using a model with too many parameters (e.g., a deep neural network with many layers) can lead to overfitting.\n",
      "- **Small training dataset:** When the training data is small, the model has fewer examples to learn from and may overfit to the existing ones.\n",
      "- **High noise in the data:** If the data is noisy, the model may learn the noise instead of the true patterns.\n",
      "- **Overly sophisticated features:** Complex features can increase the model's ability to fit the training data but might not generalize well.\n",
      "\n",
      "**5. Consequences of Overfitting:**\n",
      "\n",
      "- **Poor performance on unseen data:** The model will struggle to predict accurately on new data.\n",
      "- **Unreliable predictions:** The model's predictions will be highly sensitive to small changes\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Setting our parameters\n",
    "custom_config = genai.types.GenerationConfig(max_output_tokens=500, temperature=1.0)\n",
    "\n",
    "user_prompt = \"\"\"What is overfitting in data science? Explain in detail.\"\"\"\n",
    "\n",
    "# Passing our custom parameters to the generate_content method\n",
    "response = model.generate_content(user_prompt, generation_config=custom_config)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ff8b205-f447-4725-815e-e898d88ac237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Feature Selection: The Art of Choosing the Right Variables\n",
      "\n",
      "In data science, feature selection is a crucial process that involves **identifying and selecting the most relevant features (variables) from a dataset** for building a predictive model. It's like choosing the right ingredients for a recipe – the right features can significantly improve model performance, while irrelevant ones can lead to noise and overfitting.\n",
      "\n",
      "**Why is Feature Selection Important?**\n",
      "\n",
      "* **Improved Model Performance:** By removing irrelevant or redundant features, we reduce noise and complexity, leading to more accurate and robust models.\n",
      "* **Reduced Overfitting:** Overfitting occurs when a model learns the training data too well, failing to generalize to new data. Feature selection helps prevent this by simplifying the model.\n",
      "* **Faster Training and Inference:** Fewer features mean less data to process, resulting in faster model training and prediction times.\n",
      "* **Enhanced Interpretability:** Models with fewer features are easier to understand and interpret, making it easier to explain the model's predictions.\n",
      "* **Reduced Costs:**  Less data means lower storage and processing costs.\n",
      "\n",
      "**Types of Feature Selection Techniques:**\n",
      "\n",
      "Feature selection techniques can be broadly categorized into three main types:\n",
      "\n",
      "1. **Filter Methods:** These methods evaluate features independently based on their intrinsic properties, without considering the model. Examples include:\n",
      "    * **Univariate Feature Selection:**  Measures the relationship between each feature and the target variable using statistical tests like chi-squared, ANOVA, or correlation coefficients.\n",
      "    * **Information Gain:** Measures the reduction in entropy (uncertainty) when a feature is used to split the data.\n",
      "    * **Mutual Information:** Measures the dependency between two variables.\n",
      "\n",
      "2. **Wrapper Methods:** These methods use a specific machine learning model to evaluate the performance of different feature subsets. They are more computationally expensive but often yield better results. Examples include:\n",
      "    * **Forward Selection:** Starts with an empty set of features and iteratively adds the feature that improves the model performance the most.\n",
      "    * **Backward Elimination:** Starts with all features and iteratively removes the feature that has the least impact on model performance.\n",
      "    * **Recursive Feature Elimination (RFE):**  Repeatedly removes features based on their importance scores until a desired number of features remains.\n",
      "\n",
      "3. **Embedded Methods:** These methods integrate feature selection into the model training process itself. They are often more efficient and provide a good balance between performance and interpretability. Examples include:\n",
      "    * **Lasso Regression:**  A linear regression model that uses L1 regularization to shrink the coefficients of irrelevant features to zero.\n",
      "    * **Decision Trees:**  Tree-based models naturally perform feature selection by prioritizing features that lead to the most informative splits.\n",
      "    * **Random Forest:**  An ensemble of decision trees that can be used to identify important features based on their frequency of selection across multiple trees.\n",
      "\n",
      "**Choosing the Right Technique:**\n",
      "\n",
      "The best feature selection technique depends on the specific dataset, the chosen model, and the desired trade-off between performance, interpretability, and computational cost.\n",
      "\n",
      "**Considerations for Feature Selection:**\n",
      "\n",
      "* **Data Type:** Different techniques are suitable for different data types (e.g., numerical, categorical).\n",
      "* **Data Size:**  Computational cost can be a factor for large datasets.\n",
      "* **Model Complexity:**  More complex models may require more features.\n",
      "* **Domain Expertise:**  Understanding the underlying domain can help guide feature selection.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Feature selection is a crucial step in building effective machine learning models. By carefully selecting the most relevant features, we can improve model performance, reduce overfitting, and enhance interpretability. Choosing the right technique and considering the specific context of the problem are essential for achieving optimal results.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setting our parameters\n",
    "custom_config = genai.types.GenerationConfig(temperature=0.1, top_p=0.1, top_k=32)\n",
    "\n",
    "user_prompt = \"\"\"What is feature selection in data science? Explain in detail.\"\"\"\n",
    "\n",
    "# Passing our custom parameters to the generate_content method\n",
    "response = model.generate_content(user_prompt, generation_config=custom_config)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00edd75-19cc-4f41-923a-f8b49c9e5d94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
